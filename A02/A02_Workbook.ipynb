{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63b830f",
   "metadata": {},
   "source": [
    "# HLCV Assignment 2\n",
    "\n",
    "### Prequel\n",
    "This notebook contains skeletons that you are supposed to fill in (watch out for <font color='red'>**TODO**</font> tags). In general, you are expected to implement methods yourself. For example, when asked to implement a method computing histograms you can use numpy array functions that help you implement this task, but not use the numpy implementation `np.histogram` for your solution. To submit your assignment, upload your completed notebook and a PDF report (use the provided Latex template with, for example, [Overleaf](http://overleaf.com)) that contains your observations.\n",
    "\n",
    "### Setting\n",
    "In this exercise you will train (i) shallow classifiers and (ii) deep learning-based classifiers on a dataset containing 10 different types of clothing articles and compare their performance with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33398b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision, matplotlib.pyplot as plt, sklearn, numpy as np, tqdm.notebook as tqdm, time\n",
    "from IPython. display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4ab263-3709-44aa-bf18-2d9ea0120b1c",
   "metadata": {},
   "source": [
    "# Part I: SVM and Decision Boundaries\n",
    "\n",
    "In this part of the exercise you will get better acquainted with the SVM algorithm using an artificially generated 2D classification problem. As you might recall from the lecture the problem setting is the following. We are given a training dataset $\\{(X_i, y_i), i = 1, . . . ,N\\}$, where $X_i$ is an *M*-dimensional feature vector and $y_i \\in \\{−1, 1\\}$ is a label which denotes whether the corresponding point should be classified as negative or as positive. Further, we assume that the classification boundary has the form $y(X) = W^TX + w_0$.\n",
    "\n",
    "The new point is classified as positive if $y(X) > 0$ and negative otherwise.\n",
    "\n",
    "You can use the provided function to generate a simple 2D dataset in which positive and negative training points are sampled from 2 distinct Gaussian distributions. The last two parameters of this function allow to control the variance of the points, so that both linearly separable and linearly non-separable datasets can be generated.\n",
    "\n",
    "### a) SVM Training\n",
    "\n",
    "Use the following function to generate 2D Gaussian data and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80451a22-fbfd-4b29-bc63-524101b343d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gauss_data(N, mean_pos, mean_neg, std_pos, std_neg):\n",
    "    state = np.random.RandomState(seed=42)\n",
    "    pos = np.stack((\n",
    "        state.normal(size=N, loc=mean_pos, scale=std_pos),\n",
    "        state.normal(size=N, loc=0, scale=1)\n",
    "    )).T\n",
    "    neg = np.stack((\n",
    "        state.normal(size=N, loc=mean_neg, scale=std_neg),\n",
    "        state.normal(size=N, loc=0, scale=1)\n",
    "    )).T\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd684f09-9f2b-4969-8e60-740f343e756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos, data_neg = generate_gauss_data(\n",
    "    N = 500,\n",
    "    mean_pos = -4,\n",
    "    mean_neg =  4,\n",
    "    std_pos = 1,\n",
    "    std_neg = 1\n",
    ")\n",
    "plt.scatter(data_pos[:,0], data_pos[:,1])\n",
    "plt.scatter(data_neg[:,0], data_neg[:,1])\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.grid(linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7748d8d-1922-42da-8463-96d9d6806b5f",
   "metadata": {},
   "source": [
    "<font color='red'>**TODO:**</font> The following function trains an SVM on your generated Gaussian data. Make yourself familiar with the parameters of sklearn's SVM implementation (see https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html). Then, run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fb24dc-ac7d-4b88-9bf5-2b76569ac6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(data_pos, data_neg, svm_pars):\n",
    "    data = np.concatenate((data_pos, data_neg))\n",
    "    labels = np.concatenate((\n",
    "        np.ones(len(data_pos)),\n",
    "        -np.ones(len(data_neg))\n",
    "    ))\n",
    "\n",
    "    clf = sklearn.svm.SVC(**svm_pars)\n",
    "    return clf.fit(X=data, y=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f51a53-f683-4f24-8b22-378c5af84170",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = train_svm(\n",
    "    data_pos = data_pos,\n",
    "    data_neg = data_neg,\n",
    "    svm_pars  = {\n",
    "        \"kernel\": \"linear\",\n",
    "        \"probability\": True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a76b2-966f-4473-8e7e-f418ea390188",
   "metadata": {},
   "source": [
    "### b) SVM Visualization\n",
    "\n",
    "<font color='red'>**TODO:**</font> Adjust the next cell to not only plot the training dataset, but also the support vectors and decision boundary of the trained SVM. The attribute section of the SVM documentary might help you with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e11d93f-8fd8-4452-951c-f5321d33e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svm(data_pos, data_neg, clf, title=None):\n",
    "    # plot the training data\n",
    "    \n",
    "    plt.scatter(data_pos[:,0], data_pos[:,1])\n",
    "    plt.scatter(data_neg[:,0], data_neg[:,1])\n",
    "\n",
    "    # plot the decision boundary\n",
    "\n",
    "    # ...\n",
    "\n",
    "    # plot the support vectors\n",
    "\n",
    "    # ...\n",
    "    \n",
    "    plt.grid(linestyle=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3d2a4d-ee99-4fc6-a6ad-56f3b8af8dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svm(data_pos=data_pos, data_neg=data_neg, clf=clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e324d08-e960-4d65-8959-927e8e5fa8af",
   "metadata": {},
   "source": [
    "### c) Linearly non-separable data\n",
    "<font color='red'>**TODO:**</font> Find a setting where the data is not linearly separable anymore by changing the standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132c427-c00a-4951-9f75-73442223569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos, data_neg = generate_gauss_data(\n",
    "    # add your parameters here\n",
    ")\n",
    "plt.scatter(data_pos[:,0], data_pos[:,1])\n",
    "plt.scatter(data_neg[:,0], data_neg[:,1])\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.grid(linestyle=\"--\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604005ff-40cc-482d-b645-32faff7eb199",
   "metadata": {},
   "source": [
    "<font color='red'>**TODO:**</font> Train different SVM on the linearly non-separable data by varying their *C* parameter. Visualize their resulting decision boundaries and support vectors. What do you observe? What is the role of *C* in the SVM classification algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bec150-440d-4fc8-8596-50c2d6616674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5400bec",
   "metadata": {},
   "source": [
    "# Part II: Image Classification with Fashion-MNIST\n",
    "\n",
    "### Download Fashion-MNIST and show samples.\n",
    "[Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) is a (more challenging MNIST-like) dataset that contains 28x28 grayscale images of 10 different types of clothing articles, hence **10** classes. There is a training dataset containing 60k images and a test dataset containing 10k images. Torchvision provides functionality to download both datasets (see next cell), so it is sufficient to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b42c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = torchvision.datasets.FashionMNIST(\"data\", train=True,  download=True)\n",
    "dataset_test  = torchvision.datasets.FashionMNIST(\"data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc2e541",
   "metadata": {},
   "source": [
    "Lets extract the images into numpy arrays. Also, show some sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c7527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset_train.data.numpy()\n",
    "y_train = dataset_train.targets.numpy()\n",
    "X_test  = dataset_test.data.numpy()\n",
    "y_test  = dataset_test.targets.numpy()\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "f, ax = plt.subplots(10,10, figsize=(15,15))\n",
    "for c in range(10):\n",
    "    for i in range(10):\n",
    "        ax[c,i].imshow(X_train[y_train==c][i], interpolation=\"none\", cmap=\"gray\")\n",
    "        if i==0:\n",
    "            ax[c,i].set_ylabel(dataset_train.classes[c])\n",
    "        if i==9:\n",
    "            ax[c,i].yaxis.set_label_position(\"right\")\n",
    "            ax[c,i].set_ylabel(f\"c={c}\")\n",
    "        ax[c,i].set_yticks([])\n",
    "        ax[c,i].set_xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ac949d",
   "metadata": {},
   "source": [
    "We split the training dataset into a split used for training (50k images) and another split used for validation (10k images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size = 10_000,\n",
    "    random_state = 42,\n",
    "    stratify = y_train\n",
    ")\n",
    "\n",
    "np.unique(y_val, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f110ee0e",
   "metadata": {},
   "source": [
    "### a) Shallow Learning - Image as input features\n",
    "<font color='red'>**TODO:**</font> Choose at least 3 classifiers (of which one is Logistic Regression) from sklearn and train these models on the **training split**. Tune possible hyperparameters on the **validation split**. Finally, report your best found model (according to validation) with their corresponding performance (i) on the **training split**, (ii) on the **validation split**, and (iii) on the **test data**. Use `random_state=42` when initializing non-deterministic classifiers to get reproducable results. Compose your results (and found hyperparameters) in a table in your report.\n",
    "\n",
    "You can find possible classifiers here: https://scikit-learn.org/stable/supervised_learning.html\n",
    "\n",
    "Train, tune, and test different classifiers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e277002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an example printing the number of correctly classified training samples of a Logistic Regression.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=42, max_iter=200)\n",
    "clf.fit(\n",
    "    X = X_train.reshape(len(X_train), -1),\n",
    "    y = y_train\n",
    ")\n",
    "pred_train = clf.predict(X=X_train.reshape(len(X_train), -1))\n",
    "print((pred_train==y_train).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e9b04d-2ef1-4e4b-b192-cca9c370195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and tune classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fba41c-4040-47a3-9b1e-ab23fab6eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate the generalization error of your best found hyperparameter combinations for each classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430695f4",
   "metadata": {},
   "source": [
    "### b) Deep Learning - Learn to Extract Features from Images\n",
    "### Defining our classification network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a7ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, kernel_size=3, out_channels=16, pool_size=7):\n",
    "        # inherit from torch.nn.Module\n",
    "        super(type(self), self).__init__()\n",
    "        assert (28%pool_size) == 0, \"pool_size must be a divisible of image dimensions (28)\"\n",
    "        self.conv = torch.nn.Conv2d(\n",
    "            kernel_size = kernel_size,\n",
    "            in_channels = 1,\n",
    "            out_channels = out_channels,\n",
    "            padding = \"same\"\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(out_channels*((28//pool_size)**2), 10)\n",
    "        self.pool_size = pool_size\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input image size: x.shape = Bx1x28x28 (Batchsize x Channels x Height x Width)\n",
    "        x = self.conv(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        # feature maps size: x.shape = Bx16x28x28\n",
    "        # reduce spatial dimensionality of feature maps\n",
    "        x = torch.nn.functional.avg_pool2d(x, kernel_size=self.pool_size)\n",
    "        # feature maps size: x.shape = Bx16x4x4\n",
    "        # flatten features for input to linear layer\n",
    "        x_feat = x.reshape(len(x), -1)\n",
    "        # dimensionality of features is now 16*4*4 = Bx256\n",
    "        # previously, the dimensionality of inputting the plain images was: 28*28=784\n",
    "        y_logits = self.linear(x_feat)\n",
    "        # now we have prediction scores for each class: x.shape == Bx10\n",
    "        return y_logits, x_feat\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.conv.reset_parameters()\n",
    "        self.linear.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a38fe",
   "metadata": {},
   "source": [
    "### Training our classification network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc9e6b",
   "metadata": {},
   "source": [
    "The following cells contain utility functions.\n",
    "- `plot_perf`: You can collect your measures into lists and use the following function to plot your results.\n",
    "- `save_state`: Use this function to save the state of a network.\n",
    "- `load_state`: Use this function to create a CNNClassifier from a saved state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063c7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perf(train:list, val:list , name:list, share_axis=False):\n",
    "    assert len(train) == len(val) == len(name)\n",
    "    \n",
    "    f, host = plt.subplots(figsize=(8,5))\n",
    "    handles = []\n",
    "    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    \n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.grid(linestyle=\"--\")\n",
    "    \n",
    "    for i in range(len(train)):\n",
    "        ax = plt.gca()\n",
    "        if not share_axis:\n",
    "            if i == 0:\n",
    "                ax = host\n",
    "            else:\n",
    "                ax = host.twinx()\n",
    "            ax.set_ylabel(name[i], c=colors[i])\n",
    "            ax.tick_params(axis=\"y\", colors=colors[i])\n",
    "        \n",
    "        handles += ax.plot(train[i], label=f\"{name[i]}, train\", c=colors[i])\n",
    "        handles += ax.plot(val[i], label=f\"{name[i]}, val\", c=colors[i], linestyle=\"--\")\n",
    "    \n",
    "    plt.legend(handles=handles, bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb2c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_state(network, optimizer, name):\n",
    "    torch.save({\n",
    "        \"net\": network.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"params\": {\n",
    "            \"kernel_size\": network.conv.kernel_size,\n",
    "            \"out_channels\": network.conv.out_channels,\n",
    "            \"pool_size\": network.pool_size\n",
    "        },\n",
    "        \"measures\": {measures}\n",
    "    }, \"savestate_{name}.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899f63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state(name, map_location):\n",
    "    load = torch.load(\"savestate_{name}.torch\", map_location=map_location)\n",
    "    network = CNNClassifier(**load[\"params\"])\n",
    "    network.load_state(load[\"net\"])\n",
    "    return network, load[\"optimizer\"], measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049ce643",
   "metadata": {},
   "source": [
    "Preparing data for Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5287ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = torch.from_numpy(X_train).float()/255, torch.from_numpy(X_val).float()/255\n",
    "# Pytorch models expect input in the shape of BxCxHxW, therefore we add a channel dimension\n",
    "data_train, data_val = data_train.unsqueeze(dim=1), data_val.unsqueeze(dim=1)\n",
    "data_test, target_test = (torch.from_numpy(X_test).float()/255).unsqueeze(1), torch.from_numpy(y_test)\n",
    "target_train, target_val = torch.from_numpy(y_train), torch.from_numpy(y_val)\n",
    "\n",
    "dataset_train = torch.utils.data.TensorDataset(data_train, target_train)\n",
    "dataset_val   = torch.utils.data.TensorDataset(data_val,   target_val)\n",
    "dataset_test  = torch.utils.data.TensorDataset(data_test,  target_test)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset = dataset_train,\n",
    "    batch_size = 64,\n",
    "    shuffle = True,\n",
    ")\n",
    "\n",
    "dataloader_val = torch.utils.data.DataLoader(\n",
    "    dataset = dataset_val,\n",
    "    batch_size = 64,\n",
    "    shuffle = False,\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset = dataset_test,\n",
    "    batch_size = 64,\n",
    "    shuffle = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f033cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8668b1b",
   "metadata": {},
   "source": [
    "Create the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df779414",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = CNNClassifier(\n",
    "    kernel_size = 3,\n",
    "    out_channels = 100,\n",
    "    pool_size = 7\n",
    ")\n",
    "# move to GPU if GPU is available\n",
    "if use_gpu and torch.cuda.is_available():\n",
    "    network = network.cuda()\n",
    "\n",
    "print(network)\n",
    "print()\n",
    "print(\"\\n\".join([f\"{name}: {p.shape} -> {p.numel()} parameters\" for name, p in network.named_parameters()]))\n",
    "print()\n",
    "print(f\"Total number of parameters: {sum([p.shape.numel() for p in network.parameters()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1111467",
   "metadata": {},
   "source": [
    "Create optimizer and loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea56fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(network.parameters())\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e62e17",
   "metadata": {},
   "source": [
    "### Training loop\n",
    "\n",
    "<font color='red'>**TODO:**</font> Adjust the training loop by implementing the following functionalities:\n",
    "- Currently, the only measurements collected is the training loss. Add other performance measures.\n",
    "- Currently, the validation data is not evaluated. Add performance measures for the validation data.\n",
    "\n",
    "You can use function `plot_perf` to plot your measurements and `save_state` to save your network at any time (e.g. when the validation measures are good).\n",
    "\n",
    "<font color='red'>**TODO:**</font> Find a combination of hyperparameters that works well for your network. Report the hyperparameters you tried with their corresponding training and validation measures in a table in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.reset_parameters()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "# example to show how plot_perf works, delete the following two lines after you understand the function\n",
    "train_measurement_x = [1,2,3,4,5]\n",
    "val_measurement_x = [2,1,4,3,5]\n",
    "time_start = time.time()\n",
    "epochs = 100\n",
    "\n",
    "for epoch in tqdm.trange(epochs):\n",
    "    train_loss = 0\n",
    "    \n",
    "    # 1. Train the network\n",
    "    for x, y in dataloader_train:\n",
    "        # delete previous gradient calculations\n",
    "        optimizer.zero_grad()\n",
    "        # move to GPU if GPU is available\n",
    "        if use_gpu and torch.cuda.is_available():\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        \n",
    "        # predict class logits for each image in the batch\n",
    "        y_pred, x_feat = network(x)\n",
    "        # compute the loss\n",
    "        L = loss(y_pred, y)\n",
    "        # compute gradients\n",
    "        L.backward()\n",
    "        # change parameters of the network\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += L.item()\n",
    "        \n",
    "    train_loss /= len(dataloader_train.dataset)\n",
    "    \n",
    "    # 2. Validate the network\n",
    "    with torch.no_grad(): # we don't need gradients: speeds up computations\n",
    "        for x, y in dataloader_val:\n",
    "            ...\n",
    "    \n",
    "    # 3. collect all measures\n",
    "    train_losses += [train_loss]\n",
    "    \n",
    "    # clear cell output to replot progress\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # some output\n",
    "    print(f\"[{epoch:>2}] Train loss: {train_loss:.5f}\")\n",
    "    time_past = time.time() - time_start\n",
    "    time_per_epoch = time_past / (epoch+1)\n",
    "    eta = (epochs-1-epoch) * time_per_epoch\n",
    "    print(f\"[{epoch:>2}] Time: {time_past:.1f}s, Time-per-Epoch: {time_per_epoch:.1f}s, eta: {eta:.1f}s\")\n",
    "    \n",
    "    # takes lists of lists as input:\n",
    "    # each item of argument ´train´ expects a corresponding item in ´val´.\n",
    "    plot_perf(\n",
    "        train = [train_losses, train_measurement_x],\n",
    "        val = [val_losses, val_measurement_x],\n",
    "        name = [\"loss\", \"measurement x\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f8da1-f621-4eb3-9815-d5a70e9cbe37",
   "metadata": {},
   "source": [
    "<font color='red'>**TODO:**</font> Approximate the generalization performance of your best network. There is no code for this so far, you have to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b9640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your network's performance on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac3db1",
   "metadata": {},
   "source": [
    "### c) Visualizing kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19709794",
   "metadata": {},
   "source": [
    "<font color='red'>**TODO:**</font> Visualize the kernels of one of your models (do not use a model that has too many kernels, but at least 9). Write in your report what you observe looking at the kernels and try to speculate about the features they extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafb3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kernels(network):\n",
    "    kernels, bias = list(network.conv.parameters())\n",
    "    kernels = kernels.detach().cpu()\n",
    "    # scale between [-1,1]\n",
    "    kernels = kernels / kernels.abs().reshape(len(kernels), -1).max(dim=1)[0].unsqueeze(1).unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    # plot kernels\n",
    "    plt.imshow(\n",
    "        torchvision.utils.make_grid(\n",
    "            kernels,\n",
    "            nrow = int(np.ceil(np.sqrt(len(kernels)))),\n",
    "            pad_value = .0\n",
    "        ).permute(1,2,0).mean(dim=2),\n",
    "        cmap = \"bwr\",\n",
    "        vmin = -1,\n",
    "        vmax = 1\n",
    "    )\n",
    "    plt.axis(\"off\")\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5224c6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kernels(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a78ae",
   "metadata": {},
   "source": [
    "### d) Classify Learned Features with ML Models\n",
    "<font color='red'>**TODO:**</font> Implement a function that - given a dataloader and network - extracts features (after the convolutional layer) for each image. Collect the features to generate training, validation, and test datasets. Use these datasets to train and evaluate your classifiers of Q1. Summarize your results in a table in your report and answer the following questions:\n",
    "- How did the performance of each classifier evolve with the new set of features?\n",
    "- Why do you think their performance improves / deteriorates (for each case)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57962397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataloader, network):\n",
    "    features = []\n",
    "    targets = []\n",
    "    \n",
    "    for x, y in dataloader:\n",
    "        targets += [y.detach().cpu().numpy()]\n",
    "        ...\n",
    "        \n",
    "    return np.concatenate(features), np.concatenate(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d5152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f308b3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models on generated datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1bda82",
   "metadata": {},
   "source": [
    "### e) Deeper Learning\n",
    "<font color='red'>**TODO:**</font> The network in Q2 is still quite shallow. You can increase its depth by, for example, adding more convolutional layers. Extend the code (or create a new class) such that you are able to add more convolutional and more linear layers. Train a deeper network. How good can your network become?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conduct your experiments here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
